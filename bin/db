#!/Users/wakita/.venvs/vis/bin/python

import argparse
import datetime
import os
from pathlib import Path
import pickle
import sys
import time

import pandas as pd
import gspread
import gdown

from pyperclip import copy


# Google Spreadsheet のダウンロード

ROOT = Path(__file__).parent.parent.resolve()

CACHE_SUB = ROOT.joinpath('files', 'submission', 'submission.xlsx')
CACHE_REG = ROOT.joinpath('files', 'registration', 'registration.xlsx')

def download(args):
    gc = gspread.service_account()
    print('投稿状況の Google Spreadsheet をダウンロード中')
    book = gc.open_by_key('1nAlOjtGwKWGbU_QE_JeiB__wJs6y46hUIi4erpRO-XM')
    sub = pd.DataFrame(book.get_worksheet(0).get_all_records())
    sub.drop(sub[sub['REMARK'].isin(set(['test', 'duplicate', 'cancel']))].index, inplace=True)
    with open(CACHE_SUB, 'wb') as w:
        sub.to_excel(w)

    '''
    print('参加申込状況の Google Spreadsheet をダウンロード中')
    book = gc.open_by_key('147n__4QXF_xIEfXjPEAzxQpJTx18QrQO80TTtQ6_7ts')
    reg = pd.DataFrame(book.get_worksheet(0).get_all_records())
    sub.drop(reg[reg['REMARK'].isin(set(['test', 'duplicate', 'cancel']))].index, inplace=True)
    with open(CACHE_REG, 'wb') as w:
        reg.to_excel(w)
    '''


def download_papers(args):
    load()
    SUBMISSION = ROOT.joinpath('files', 'submission')
    SUBMISSION_PKL = SUBMISSION.joinpath('pdf.pkl')
    if os.path.exists(SUBMISSION_PKL):
        with open(SUBMISSION_PKL, 'rb') as f:
            submissions = pickle.load(f)
    else:
        submissions = {}

    for id, submission in sub.iterrows():
        pdfs = submission['発表論文']
        if pd.isna(pdfs): continue
        pdf = pdfs.split(', ')[-1]
        pdf_id = pdf.split('id=')[-1]
        if pdf_id != submissions.get(id, ''):
            print(f'Downloading paper: #{id}')
            gdown.download(f'https://drive.google.com/uc?id={pdf_id}',
                           f'{SUBMISSION}/{id:03d}.pdf',
                           quiet=True)
            submissions[id] = pdf_id

    with open(SUBMISSION_PKL, 'wb') as w:
        pickle.dump(submissions, w)


# スプレッドシートの読み込み

sub = None
def load():
    global sub
    sub = pd.read_excel(CACHE_SUB, index_col='PAPER_ID')

# 検索

def search(A):
    load()
    try:
        if A.key in set(['id', 'PAPER_ID']):
            paper = sub.loc[int(A.value)]
        elif A.key in set(['title', '和文題目']):
            paper = sub[sub['和文題目'].str.contains(A.value)].iloc[0]
        elif A.key in set(['name', '姓', '姓 (1)']):
            paper = sub[sub['姓 (1)'].str.contains(A.value)].iloc[0]
    except:
        print('該当する発表が見つかりませんでした。')
        return

    print(f'氏名: {paper["姓 （例：山田）"]} {paper["名 （例：花子）"]}, 所属機関: {paper["所属機関"]}')
    print(f'和文題目: {paper["和文題目"]}')
    print(f'編集URL: {paper["EDIT_URL"]}')
    uploads = paper["発表論文"]
    if type(uploads) == str:
        uploads = uploads.split(', ')
        print(f'論文URL #{len(uploads)}: {uploads[-1]}')

def remarks(A):
    print(sub[~(sub['REMARK'].isna())])

# コマンド行処理

P = argparse.ArgumentParser(description='発表申し込みDBへのアクセス')

SP = P.add_subparsers(help='サブコマンドを実行する')
P_download = SP.add_parser('download', aliases=['dl'])
P_download.set_defaults(handler=download)

P_search = SP.add_parser('search')
P_search.add_argument('key', choices='id PAPER_ID name title'.split(), help='検索対象の属性')
P_search.add_argument('value', help='検索したい値')
P_search.set_defaults(handler=search)

P_papers = SP.add_parser('papers')
P_papers.set_defaults(handler=download_papers)

P_remarks = SP.add_parser('remarks')
P_remarks.set_defaults(handler=remarks)

args = P.parse_args()
if hasattr(args, 'handler'): args.handler(args)
else: parser.print_help()

# vi: ft=python
